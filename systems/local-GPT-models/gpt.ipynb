{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from pydantic import BaseModel\n",
    "url = open(\"local_models_path.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 4) (790, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>dataset</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to KBismarck.org! This is a community ...</td>\n",
       "      <td>Information/Explanation</td>\n",
       "      <td>EN-GINCO</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why graft thrives in postconflict zones &lt;p&gt; A ...</td>\n",
       "      <td>News</td>\n",
       "      <td>EN-GINCO</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   labels  \\\n",
       "0  Welcome to KBismarck.org! This is a community ...  Information/Explanation   \n",
       "1  Why graft thrives in postconflict zones <p> A ...                     News   \n",
       "\n",
       "    dataset language  \n",
       "0  EN-GINCO  English  \n",
       "1  EN-GINCO  English  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the test datasets from the GitHub repositories (access to them is obtained by request to the AGILE repository owner)\n",
    "\n",
    "en_ginco = pd.read_json(\"../../datasets/EN-GINCO-test-dataset/EN-GINCO.jsonl\", lines=True)\n",
    "x_ginco = pd.read_json(\"../../datasets/X-GINCO-test-set/X-GINCO.jsonl\", lines=True)\n",
    "\n",
    "print(en_ginco.shape, x_ginco.shape)\n",
    "\n",
    "en_ginco.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_local_model(model, prompt, url=url):\n",
    "\n",
    "\tclass ReponseStructure(BaseModel):\n",
    "\t\tgenre: int\n",
    "\n",
    "\tdata = {\n",
    "\t    \"model\": model,\n",
    "\t    \"prompt\": prompt,\n",
    "\t    \"stream\": False,\n",
    "\t    \"temperature\": 0,\n",
    "\t    \"format\": ReponseStructure.model_json_schema()\n",
    "\t}\n",
    "\n",
    "\theaders = {\"Content-Type\": \"application/json\",}\n",
    "\tresponse = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "\treturn response.json()[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gemma3:27b\", \"gemma2:27b\", \"deepseek-r1:14b\", \"llama3.3:latest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gpt(df_test_name, gpt_model):\n",
    "\n",
    "\tdfs = {\n",
    "\t\t\"en-ginco\": en_ginco,\n",
    "\t\t\"x-ginco\": x_ginco\n",
    "\t}\n",
    "\n",
    "\tdf = dfs[df_test_name]\n",
    "\n",
    "\tresponses = []\n",
    "\t\n",
    "\ttexts = df[\"text\"].to_list()\n",
    "\n",
    "\tstart_time = time.time()\n",
    "\n",
    "\tlabels_dict = {\n",
    "\t\t0: \"Other\",\n",
    "\t\t1: \"Information/Explanation\",\n",
    "\t\t2: \"News\",\n",
    "\t\t3: \"Instruction\",\n",
    "\t\t4: \"Opinion/Argumentation\",\n",
    "\t\t5: \"Forum\",\n",
    "\t\t6: \"Prose/Lyrical\",\n",
    "\t\t7: \"Legal\",\n",
    "\t\t8: \"Promotion\"\n",
    "\t}\n",
    "\n",
    "\tfor text in texts:\n",
    "\t\tcurrent_prompt = f\"\"\"\n",
    "\t\t\t\t### Task\n",
    "\t\t\t\tYour task is to classify the following text according to genre. Genres are text types, defined by the function of the text, authorâ€™s purpose and form of the text. Always provide a label, even if you are not sure.\n",
    "\n",
    "\t\t\t\t### Output format\n",
    "\t\t\t\t\tReturn a valid JSON dictionary with the following key: 'genre' and a value should be an integer which represents one of the labels according to the following dictionary: {labels_dict}.\n",
    "\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tText: '{text}'\n",
    "\t\t\t\"\"\"\n",
    "\n",
    "\t\tinitial_response= run_local_model(gpt_model, current_prompt, url=url)\n",
    "\n",
    "\t\tresponse = initial_response.replace(\"\\n\", \"\")\n",
    "\t\tresponse = response.replace(\"\\t\", \"\")\n",
    "\n",
    "\t\t# Convert the string into a dictionary\n",
    "\t\tresponse = json.loads(response)\n",
    "\n",
    "\t\t# Get out a label\n",
    "\t\ttry:\n",
    "\t\t\tpredicted = labels_dict[response[\"genre\"]]\n",
    "\t\t\tresponses.append(predicted)\n",
    "\t\t# add a possibility of something going wrong\n",
    "\t\texcept:\n",
    "\t\t\tpredicted = initial_response\n",
    "\t\t\tprint(\"error with extracting a label:\")\n",
    "\t\t\tprint(initial_response)\n",
    "\t\t\tresponses.append(predicted)\n",
    "\n",
    "\tend_time = time.time()\n",
    "\telapsed_time_min = end_time-start_time\n",
    "\n",
    "\tprint(f\"Prediction finished. It took {elapsed_time_min/60} min for {df.shape[0]} instances - {elapsed_time_min/df.shape[0]} s per instance.\")\n",
    "\n",
    "\t# Create a json with results\n",
    "\n",
    "\tcurrent_results = {\n",
    "\t\t\"system\": gpt_model,\n",
    "\t\t\"predictions\": [\n",
    "\t\t\t{\n",
    "\t\t\t\"train\": \"X-GENRE (train split)\",\n",
    "\t\t\t\"test\": \"{}\".format(df_test_name),\n",
    "\t\t\t\"predictions\": responses,\n",
    "\t\t\t}\n",
    "\t\t]\n",
    "\t\t}\n",
    "\n",
    "\t# Save the results as a new json\n",
    "\twith open(\"submissions/submission-{}-{}.json\".format(gpt_model, df_test_name), \"w\") as file:\n",
    "\t\tjson.dump(current_results, file)\n",
    "\n",
    "\tprint(\"Classification with {} on {} finished.\".format(gpt_model, df_test_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in [\"en-ginco\", \"x-ginco\"]:\n",
    "\tfor model in models:\n",
    "\t\tprint(model)\n",
    "\t\tpredict_gpt(test, model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emma_nova2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
