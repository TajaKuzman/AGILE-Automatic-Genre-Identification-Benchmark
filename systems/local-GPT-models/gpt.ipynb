{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from pydantic import BaseModel\n",
    "url = open(\"local_models_path.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 4) (790, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>dataset</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to KBismarck.org! This is a community ...</td>\n",
       "      <td>Information/Explanation</td>\n",
       "      <td>EN-GINCO</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why graft thrives in postconflict zones &lt;p&gt; A ...</td>\n",
       "      <td>News</td>\n",
       "      <td>EN-GINCO</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   labels  \\\n",
       "0  Welcome to KBismarck.org! This is a community ...  Information/Explanation   \n",
       "1  Why graft thrives in postconflict zones <p> A ...                     News   \n",
       "\n",
       "    dataset language  \n",
       "0  EN-GINCO  English  \n",
       "1  EN-GINCO  English  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the test datasets from the GitHub repositories (access to them is obtained by request to the AGILE repository owner)\n",
    "\n",
    "en_ginco = pd.read_json(\"../../datasets/EN-GINCO-test-dataset/EN-GINCO.jsonl\", lines=True)\n",
    "x_ginco = pd.read_json(\"../../datasets/X-GINCO-test-set/X-GINCO.jsonl\", lines=True)\n",
    "\n",
    "print(en_ginco.shape, x_ginco.shape)\n",
    "\n",
    "en_ginco.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_local_model(model, prompt, url=url):\n",
    "\n",
    "\tclass ReponseStructure(BaseModel):\n",
    "\t\tgenre: int\n",
    "\n",
    "\tdata = {\n",
    "\t    \"model\": model,\n",
    "\t    \"prompt\": prompt,\n",
    "\t    \"stream\": False,\n",
    "\t    \"temperature\": 0,\n",
    "\t    \"format\": ReponseStructure.model_json_schema()\n",
    "\t}\n",
    "\n",
    "\theaders = {\"Content-Type\": \"application/json\",}\n",
    "\tresponse = requests.post(url, json=data, headers=headers)\n",
    "\n",
    "\treturn response.json()[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"gemma3:27b\", \"llama3.3:latest\", \"qwen3:32b\", \"GaMS-27B\", \"deepseek-r1:14b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gpt(df_test_name, gpt_model):\n",
    "\n",
    "\tlabels_dict = {\n",
    "\t\t\t0: \"Other\",\n",
    "\t\t\t1: \"Information/Explanation\",\n",
    "\t\t\t2: \"News\",\n",
    "\t\t\t3: \"Instruction\",\n",
    "\t\t\t4: \"Opinion/Argumentation\",\n",
    "\t\t\t5: \"Forum\",\n",
    "\t\t\t6: \"Prose/Lyrical\",\n",
    "\t\t\t7: \"Legal\",\n",
    "\t\t\t8: \"Promotion\"\n",
    "\t\t}\n",
    "\n",
    "\tlabel_dict_with_description_ext = {\n",
    "\t\t\t\"Information/Explanation - An objective text that describes or presents an event, a person, a thing, a concept etc. Its main purpose is to inform the reader about something. Common features: objective/factual, explanation/definition of a concept (x is …), enumeration. E.g., research article, encyclopedia article, informational blog, product specification, course materials, general information, job description, manual, horoscope, travel guide, glossaries, historical article, biographical story/history.\": 1,\n",
    "\t\t\t\"News - An objective or subjective text which reports on an event recent at the time of writing or coming in the near future. Common features: adverbs/adverbial clauses of time and/or place (dates, places), many proper nouns, direct or reported speech, past tense. E.g., news report, sports report, travel blog, reportage, police report, announcement.\": 2,\n",
    "\t\t\t\"Instruction - An objective text which instructs the readers on how to do something. Common features: multiple steps/actions, chronological order, 1st person plural or 2nd person, modality (must, have to, need to, can, etc.), adverbial clauses of manner (in a way that), of condition (if), of time (after …). E.g., how-to texts, recipes, technical support.\": 3,\n",
    "\t\t\t\"Opinion/Argumentation - A subjective text in which the authors convey their opinion or narrate their experience. It includes promotion of an ideology and other non-commercial causes. This genre includes a subjective narration of a personal experience as well. Common features: adjectives/adverbs that convey opinion, words that convey (un)certainty (certainly, surely), 1st person, exclamation marks. E.g., review, blog (personal blog, travel blog), editorial, advice, letter to editor, persuasive article or essay, formal speech, pamphlet, political propaganda, columns, political manifesto.\": 4,\n",
    "\t\t\t\"Forum - A text in which people discuss a certain topic in form of comments. Common features: multiple authors, informal language, subjective (the writers express their opinions), written in 1st person. E.g., discussion forum, reader/viewer responses, QA forum.\": 5,\n",
    "\t\t\t\"Prose/Lyrical - A literary text that consists of paragraphs or verses. A literary text is deemed to have no other practical purpose than to give pleasure to the reader. Often the author pays attention to the aesthetic appearance of the text. It can be considered as art. E.g., lyrics, poem, prayer, joke, novel, short story. \": 6,\n",
    "\t\t\t\"Legal - An objective formal text that contains legal terms and is clearly structured. The name of the text type is often included in the headline (contract, rules, amendment, general terms and conditions, etc.). Common features: objective/factual, legal terms, 3rd person. E.g., small print, software license, proclamation, terms and conditions, contracts, law, copyright notices, university regulation.\": 7,\n",
    "\t\t\t\"Promotion - A subjective text intended to sell or promote an event, product, or service. It addresses the readers, often trying to convince them to participate in something or buy something. Common features: contains adjectives/adverbs that promote something (high-quality, perfect, amazing), comparative and superlative forms of adjectives and adverbs (the best, the greatest, the cheapest), addressing the reader (usage of 2nd person), exclamation marks. E.g., advertisement, promotion of a product (e-shops), promotion of an accommodation, promotion of company's services, invitation to an event.\": 8,\n",
    "\t\t\t\"Other - A text that which does not fall under any of other genre categories.\": 0,\n",
    "\n",
    "\t}\n",
    "\n",
    "\tdfs = {\n",
    "\t\t\"en-ginco\": en_ginco,\n",
    "\t\t\"x-ginco\": x_ginco\n",
    "\t}\n",
    "\n",
    "\tdf = dfs[df_test_name]\n",
    "\n",
    "\tresponses = []\n",
    "\t\n",
    "\ttexts = df[\"text\"].to_list()\n",
    "\n",
    "\tstart_time = time.time()\n",
    "\n",
    "\tfor text in texts:\n",
    "\t\tcurrent_prompt = f\"\"\"\n",
    "\t\t\t\t### Task\n",
    "\t\t\t\tYour task is to classify the following text according to genre. Genres are text types, defined by the function of the text, author’s purpose and form of the text. Always provide a label, even if you are not sure.\n",
    "\n",
    "\t\t\t\t### Output format\n",
    "\t\t\t\t\tReturn a valid JSON dictionary with the following key: 'genre' and a value should be an integer which represents one of the labels according to the following dictionary: {label_dict_with_description_ext}.\n",
    "\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tText: '{text}'\n",
    "\t\t\t\"\"\"\n",
    "\n",
    "\t\tif gpt_model == \"GaMS-27B\":\n",
    "\t\t\tgpt_model_path = \"hf.co/mradermacher/GaMS-27B-Instruct-i1-GGUF:i1-Q4_K_M\"\n",
    "\t\telse:\n",
    "\t\t\tgpt_model_path = gpt_model\n",
    "\n",
    "\t\tinitial_response= run_local_model(gpt_model_path, current_prompt, url=url)\n",
    "\n",
    "\t\tresponse = initial_response.replace(\"\\n\", \"\")\n",
    "\t\tresponse = response.replace(\"\\t\", \"\")\n",
    "\n",
    "\t\t# Get out a label\n",
    "\t\ttry:\n",
    "\t\t\t# Convert the string into a dictionary\n",
    "\t\t\tresponse = json.loads(response)\n",
    "\t\t\tpredicted = labels_dict[response[\"genre\"]]\n",
    "\t\t\tresponses.append(predicted)\n",
    "\t\t# add a possibility of something going wrong\n",
    "\t\texcept:\n",
    "\t\t\tpredicted = initial_response\n",
    "\t\t\tprint(\"error with extracting a label:\")\n",
    "\t\t\tprint(initial_response)\n",
    "\t\t\tresponses.append(predicted)\n",
    "\n",
    "\tend_time = time.time()\n",
    "\telapsed_time_min = end_time-start_time\n",
    "\n",
    "\tprint(f\"Prediction finished. It took {elapsed_time_min/60} min for {df.shape[0]} instances - {elapsed_time_min/df.shape[0]} s per instance.\")\n",
    "\n",
    "\t# Create a json with results\n",
    "\n",
    "\tcurrent_results = {\n",
    "\t\t\"system\": gpt_model,\n",
    "\t\t\"predictions\": [\n",
    "\t\t\t{\n",
    "\t\t\t\"train\": \"NA (zero-shot)\",\n",
    "\t\t\t\"test\": \"{}\".format(df_test_name),\n",
    "\t\t\t\"predictions\": responses,\n",
    "\t\t\t}\n",
    "\t\t]\n",
    "\t\t}\n",
    "\n",
    "\t# Save the results as a new json\n",
    "\twith open(\"submissions/submission-{}-{}.json\".format(gpt_model, df_test_name), \"w\") as file:\n",
    "\t\tjson.dump(current_results, file)\n",
    "\n",
    "\tprint(\"Classification with {} on {} finished.\".format(gpt_model, df_test_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gemma3:27b', 'llama3.3:latest', 'qwen3:32b', 'GaMS-27B', 'deepseek-r1:14b']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepseek-r1:14b\n",
      "Prediction finished. It took 2.96041020154953 min for 272 instances - 0.653031662106514 s per instance.\n",
      "Classification with deepseek-r1:14b on en-ginco finished.\n"
     ]
    }
   ],
   "source": [
    "# Continue with prediction\n",
    "for model in ['deepseek-r1:14b']:\n",
    "\tprint(model)\n",
    "\tpredict_gpt(\"en-ginco\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma3:27b\n",
      "Prediction finished. It took 15.45708082516988 min for 790 instances - 1.173955505709105 s per instance.\n",
      "Classification with gemma3:27b on x-ginco finished.\n",
      "llama3.3:latest\n",
      "Prediction finished. It took 13.434017749627431 min for 790 instances - 1.020305145541324 s per instance.\n",
      "Classification with llama3.3:latest on x-ginco finished.\n",
      "qwen3:32b\n",
      "Prediction finished. It took 10.488041321436564 min for 790 instances - 0.7965601003622707 s per instance.\n",
      "Classification with qwen3:32b on x-ginco finished.\n",
      "GaMS-27B\n",
      "Prediction finished. It took 7.6940109173456825 min for 790 instances - 0.5843552595452417 s per instance.\n",
      "Classification with GaMS-27B on x-ginco finished.\n",
      "deepseek-r1:14b\n",
      "Prediction finished. It took 9.128555762767792 min for 790 instances - 0.6933080326152753 s per instance.\n",
      "Classification with deepseek-r1:14b on x-ginco finished.\n"
     ]
    }
   ],
   "source": [
    "for test in [\"x-ginco\"]:\n",
    "\tfor model in models:\n",
    "\t\tprint(model)\n",
    "\t\tpredict_gpt(test, model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emma_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
