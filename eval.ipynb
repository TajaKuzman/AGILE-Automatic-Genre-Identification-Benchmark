{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import f1_score\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the scores\n",
    "def testing(true, pred, labels):\n",
    "    \"\"\"\n",
    "    This function takes the list of true labels and list of predictions and evaluates the model based on comparing them.\n",
    "    It calculates micro and macro F1 scores.\n",
    "    \n",
    "    Args:\n",
    "    - y_true: list of true labels\n",
    "    - y_pred: list of predicted labels\n",
    "\n",
    "    The function returns a dictionary with micro and macro F1.\n",
    "    \"\"\"\n",
    "    y_true = true\n",
    "    y_pred = pred\n",
    "    LABELS = labels\n",
    "\n",
    "    # Calculate the scores\n",
    "    macro = f1_score(y_true, y_pred, labels=LABELS, average=\"macro\")\n",
    "    micro = f1_score(y_true, y_pred, labels=LABELS,  average=\"micro\")\n",
    "    #print(f\"Macro f1: {macro:0.3}, Micro f1: {micro:0.3}\")\n",
    "    \n",
    "    return {\"Micro F1\": micro, \"Macro F1\": macro}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predictions_to_dataset(dataset_name, results):\n",
    "    \"\"\"The function takes the dataset name and dataset dictionary and returns test dataset with predictions.\n",
    "    Args:\n",
    "    - dataset_name: should be \"x-ginco\" or \"en-ginco\"\n",
    "    \"\"\"\n",
    "    # Load the dataset from the hugging face\n",
    "    if dataset_name == \"x-ginco\":\n",
    "        test_df = pd.read_json(\"datasets/X-GINCO-test-set/X-GINCO.jsonl\", lines=True)\n",
    "    elif dataset_name == \"en-ginco\":\n",
    "        test_df = pd.read_json(\"datasets/EN-GINCO-test-dataset/EN-GINCO.jsonl\", lines=True)\n",
    "\n",
    "    # Extract predictions\n",
    "    y_pred = results[\"predictions\"][0][\"predictions\"]\n",
    "    test_df[\"y_pred\"] = y_pred\n",
    "\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the jsonl file with all results\n",
    "with open(\"results/results.json\", \"r\") as result_file:\n",
    "    results_list = json.load(result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_folder = \"systems/dummy-classifier/submissions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths to all the submission files\n",
    "submission_files = os.listdir(submission_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All evaluations completed. The results are added to the `results/results.json` file.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all submissions in the submissions directory\n",
    "for submission_file in submission_files:\n",
    "    # Use only files that start with \"submission\"\n",
    "    if \"submission-\" in submission_file:\n",
    "        # Open the submission to be evaluated\n",
    "        with open(\"{}/{}\".format(submission_folder,submission_file), \"r\") as sub_file:\n",
    "            results = json.load(sub_file)\n",
    "\n",
    "            # Get information on the dataset and the model\n",
    "            model = results[\"system\"]\n",
    "\n",
    "            dataset_name = results[\"predictions\"][0][\"test\"]\n",
    "\n",
    "            # Extract information on arguments if they exist\n",
    "            try:\n",
    "                epochs = results[\"args\"][\"num_train_epochs\"]\n",
    "                lr = results[\"args\"][\"learning_rate\"]\n",
    "            except:\n",
    "                epochs = None\n",
    "                lr = None\n",
    "\n",
    "            test_df = add_predictions_to_dataset(dataset_name, results)\n",
    "\n",
    "            # Calculate overall results\n",
    "            y_true = test_df[\"labels\"].to_list()\n",
    "            y_pred = test_df[\"y_pred\"].to_list()\n",
    "            labels = list(test_df[\"labels\"].unique())\n",
    "\n",
    "            #print(\"Evaluation: {} on {}\".format(model, dataset))\n",
    "\n",
    "            current_scores = testing(y_true, y_pred, labels)\n",
    "\n",
    "            # Calculate results for each language\n",
    "            language_results_dict = {}\n",
    "            \n",
    "            eval_langs = list(test_df[\"language\"].unique())\n",
    "\n",
    "            for lang in eval_langs:\n",
    "                cur_df = test_df[test_df[\"language\"] == lang]\n",
    "                y_true_lang = cur_df[\"labels\"].to_list()\n",
    "                y_pred_lang = cur_df[\"y_pred\"].to_list()\n",
    "                labels_lang = list(cur_df[\"labels\"].unique())\n",
    "                current_scores_lang = testing(y_true_lang, y_pred_lang, labels_lang)\n",
    "                language_results_dict[lang] = {\"Macro F1\": float(current_scores_lang[\"Macro F1\"]), \"Micro F1\": float(current_scores_lang[\"Micro F1\"])}\n",
    "\n",
    "            current_res_dict = {\"Model\": model, \"Test Dataset\": dataset_name, \"Macro F1\": current_scores[\"Macro F1\"], \"Micro F1\": current_scores[\"Micro F1\"], \"Epochs\": epochs, \"Learning Rate\": lr, \"Language-Specific Scores\": language_results_dict}\n",
    "\n",
    "            # Add the results to all results\n",
    "            results_list.append(current_res_dict)\n",
    "\n",
    "            with open(\"results/results.json\", \"w\") as new_result_file:\n",
    "                json.dump(results_list, new_result_file, indent = 2)\n",
    "\n",
    "    else:\n",
    "        print(\"Error: the following file `{}` is either not a submission file or is incorrectly named - see the `README.md` on how to prepare submission files.\")\n",
    "\n",
    "print(\"All evaluations completed. The results are added to the `results/results.json` file.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New benchmark scores:\n",
      "\n",
      "| Model               | Test Dataset   |   Macro F1 |   Micro F1 | Epochs   | Learning Rate   |\n",
      "|:--------------------|:---------------|-----------:|-----------:|:---------|:----------------|\n",
      "| dummy-stratified    | x-ginco        |      0.106 |      0.113 |          |                 |\n",
      "| dummy-most_frequent | x-ginco        |      0.029 |      0.133 |          |                 |\n",
      "\n",
      "------------------------------------------\n",
      "\n",
      "New benchmark scores:\n",
      "\n",
      "| Model               | Test Dataset   |   Macro F1 |   Micro F1 | Epochs   | Learning Rate   |\n",
      "|:--------------------|:---------------|-----------:|-----------:|:---------|:----------------|\n",
      "| dummy-stratified    | en-ginco       |      0.088 |      0.154 |          |                 |\n",
      "| dummy-most_frequent | en-ginco       |      0.032 |      0.169 |          |                 |\n",
      "\n",
      "------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe from all results\n",
    "\n",
    "result_df = pd.DataFrame(results_list)\n",
    "\n",
    "# For each dataset, create a table with results\n",
    "\n",
    "def results_table(result_df, dataset):\n",
    "    dataset_df = result_df[result_df[\"Test Dataset\"] == dataset]\n",
    "\n",
    "    # Sort values based on highest Macro F1\n",
    "    dataset_df = dataset_df.sort_values(by=\"Macro F1\", ascending=False)\n",
    "\n",
    "    # Round scores to 3 decimal places\n",
    "    dataset_df[\"Macro F1\"] = dataset_df[\"Macro F1\"].round(3)\n",
    "\n",
    "    dataset_df[\"Micro F1\"] = dataset_df[\"Micro F1\"].round(3)\n",
    "    dataset_df.drop(columns=[\"Language-Specific Scores\"], inplace=True)\n",
    "\n",
    "    print(dataset_df.to_markdown(index=False))\n",
    "\n",
    "    return dataset_df\n",
    "\n",
    "\n",
    "for dataset in [\"x-ginco\", \"en-ginco\"]:\n",
    "    print(\"New benchmark scores:\\n\")\n",
    "\n",
    "    current_df = results_table(result_df, dataset)\n",
    "    \n",
    "    # Drop column \"language-specific scores\"\n",
    "    current_df\n",
    "    \n",
    "    print(\"\\n------------------------------------------\\n\")\n",
    "\n",
    "    # Save the table in markdown\n",
    "    with open(\"results/results-{}.md\".format(dataset), \"w\") as result_file:\n",
    "        result_file.write(\"## {}\\n\\n\".format(dataset))\n",
    "        result_file.write(current_df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Dataset</th>\n",
       "      <th>Language</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Micro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dummy-most_frequent</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Albanian</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dummy-stratified</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Albanian</td>\n",
       "      <td>0.097174</td>\n",
       "      <td>0.101911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dummy-most_frequent</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Catalan</td>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.087500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dummy-stratified</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Catalan</td>\n",
       "      <td>0.145844</td>\n",
       "      <td>0.139241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dummy-most_frequent</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Croatian</td>\n",
       "      <td>0.025281</td>\n",
       "      <td>0.112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dummy-stratified</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Croatian</td>\n",
       "      <td>0.054762</td>\n",
       "      <td>0.064103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dummy-stratified</td>\n",
       "      <td>en-ginco</td>\n",
       "      <td>English</td>\n",
       "      <td>0.088143</td>\n",
       "      <td>0.154412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dummy-most_frequent</td>\n",
       "      <td>en-ginco</td>\n",
       "      <td>English</td>\n",
       "      <td>0.032145</td>\n",
       "      <td>0.169118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dummy-most_frequent</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Greek</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dummy-stratified</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Greek</td>\n",
       "      <td>0.111881</td>\n",
       "      <td>0.113924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dummy-most_frequent</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Icelandic</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dummy-stratified</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Icelandic</td>\n",
       "      <td>0.145320</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dummy-most_frequent</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Macedonian</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dummy-stratified</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Macedonian</td>\n",
       "      <td>0.064948</td>\n",
       "      <td>0.064935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dummy-most_frequent</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Maltese</td>\n",
       "      <td>0.053156</td>\n",
       "      <td>0.228571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dummy-stratified</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Maltese</td>\n",
       "      <td>0.100359</td>\n",
       "      <td>0.132353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dummy-most_frequent</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Slovenian</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dummy-stratified</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Slovenian</td>\n",
       "      <td>0.128207</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dummy-most_frequent</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>0.030220</td>\n",
       "      <td>0.137500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dummy-stratified</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>0.129092</td>\n",
       "      <td>0.140127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dummy-most_frequent</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Ukrainian</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dummy-stratified</td>\n",
       "      <td>x-ginco</td>\n",
       "      <td>Ukrainian</td>\n",
       "      <td>0.055833</td>\n",
       "      <td>0.063694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model Test Dataset    Language  Macro F1  Micro F1\n",
       "0   dummy-most_frequent      x-ginco    Albanian  0.022727  0.100000\n",
       "1      dummy-stratified      x-ginco    Albanian  0.097174  0.101911\n",
       "2   dummy-most_frequent      x-ginco     Catalan  0.020115  0.087500\n",
       "3      dummy-stratified      x-ginco     Catalan  0.145844  0.139241\n",
       "4   dummy-most_frequent      x-ginco    Croatian  0.025281  0.112500\n",
       "5      dummy-stratified      x-ginco    Croatian  0.054762  0.064103\n",
       "6      dummy-stratified     en-ginco     English  0.088143  0.154412\n",
       "7   dummy-most_frequent     en-ginco     English  0.032145  0.169118\n",
       "8   dummy-most_frequent      x-ginco       Greek  0.027778  0.125000\n",
       "9      dummy-stratified      x-ginco       Greek  0.111881  0.113924\n",
       "10  dummy-most_frequent      x-ginco   Icelandic  0.032609  0.150000\n",
       "11     dummy-stratified      x-ginco   Icelandic  0.145320  0.166667\n",
       "12  dummy-most_frequent      x-ginco  Macedonian  0.032609  0.150000\n",
       "13     dummy-stratified      x-ginco  Macedonian  0.064948  0.064935\n",
       "14  dummy-most_frequent      x-ginco     Maltese  0.053156  0.228571\n",
       "15     dummy-stratified      x-ginco     Maltese  0.100359  0.132353\n",
       "16  dummy-most_frequent      x-ginco   Slovenian  0.027778  0.125000\n",
       "17     dummy-stratified      x-ginco   Slovenian  0.128207  0.142857\n",
       "18  dummy-most_frequent      x-ginco     Turkish  0.030220  0.137500\n",
       "19     dummy-stratified      x-ginco     Turkish  0.129092  0.140127\n",
       "20  dummy-most_frequent      x-ginco   Ukrainian  0.027778  0.125000\n",
       "21     dummy-stratified      x-ginco   Ukrainian  0.055833  0.063694"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_results_dict = []\n",
    "\n",
    "for lang in [\"Albanian\", \"Catalan\", \"Croatian\", \"English\", \"Greek\", \"Icelandic\", \"Macedonian\", \"Maltese\", \"Slovenian\", \"Turkish\", \"Ukrainian\"]:\n",
    "\tfor result in results_list:\n",
    "\t\tcur_result = {\"Model\": result[\"Model\"], \"Test Dataset\": result[\"Test Dataset\"], \"Language\": lang}\n",
    "\t\ttry:\n",
    "\t\t\tcur_macro = result[\"Language-Specific Scores\"][lang][\"Macro F1\"]\n",
    "\t\t\tcur_micro = result[\"Language-Specific Scores\"][lang][\"Micro F1\"]\n",
    "\t\t\tcur_result[\"Macro F1\"] = cur_macro\n",
    "\t\t\tcur_result[\"Micro F1\"] = cur_micro\n",
    "\n",
    "\t\t\tlang_results_dict.append(cur_result)\n",
    "\t\texcept:\n",
    "\t\t\tcontinue\n",
    "\n",
    "lang_results_df = pd.DataFrame(lang_results_dict)\n",
    "\n",
    "lang_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model               | Test Dataset   | Language   |   Macro F1 |   Micro F1 |\n",
      "|:--------------------|:---------------|:-----------|-----------:|-----------:|\n",
      "| dummy-stratified    | x-ginco        | Albanian   |      0.097 |      0.102 |\n",
      "| dummy-most_frequent | x-ginco        | Albanian   |      0.023 |      0.1   |\n",
      "| Model               | Test Dataset   | Language   |   Macro F1 |   Micro F1 |\n",
      "|:--------------------|:---------------|:-----------|-----------:|-----------:|\n",
      "| dummy-stratified    | x-ginco        | Catalan    |      0.146 |      0.139 |\n",
      "| dummy-most_frequent | x-ginco        | Catalan    |      0.02  |      0.088 |\n",
      "| Model               | Test Dataset   | Language   |   Macro F1 |   Micro F1 |\n",
      "|:--------------------|:---------------|:-----------|-----------:|-----------:|\n",
      "| dummy-stratified    | x-ginco        | Croatian   |      0.055 |      0.064 |\n",
      "| dummy-most_frequent | x-ginco        | Croatian   |      0.025 |      0.112 |\n",
      "| Model               | Test Dataset   | Language   |   Macro F1 |   Micro F1 |\n",
      "|:--------------------|:---------------|:-----------|-----------:|-----------:|\n",
      "| dummy-stratified    | en-ginco       | English    |      0.088 |      0.154 |\n",
      "| dummy-most_frequent | en-ginco       | English    |      0.032 |      0.169 |\n",
      "| Model               | Test Dataset   | Language   |   Macro F1 |   Micro F1 |\n",
      "|:--------------------|:---------------|:-----------|-----------:|-----------:|\n",
      "| dummy-stratified    | x-ginco        | Greek      |      0.112 |      0.114 |\n",
      "| dummy-most_frequent | x-ginco        | Greek      |      0.028 |      0.125 |\n",
      "| Model               | Test Dataset   | Language   |   Macro F1 |   Micro F1 |\n",
      "|:--------------------|:---------------|:-----------|-----------:|-----------:|\n",
      "| dummy-stratified    | x-ginco        | Icelandic  |      0.145 |      0.167 |\n",
      "| dummy-most_frequent | x-ginco        | Icelandic  |      0.033 |      0.15  |\n",
      "| Model               | Test Dataset   | Language   |   Macro F1 |   Micro F1 |\n",
      "|:--------------------|:---------------|:-----------|-----------:|-----------:|\n",
      "| dummy-stratified    | x-ginco        | Macedonian |      0.065 |      0.065 |\n",
      "| dummy-most_frequent | x-ginco        | Macedonian |      0.033 |      0.15  |\n",
      "| Model               | Test Dataset   | Language   |   Macro F1 |   Micro F1 |\n",
      "|:--------------------|:---------------|:-----------|-----------:|-----------:|\n",
      "| dummy-stratified    | x-ginco        | Maltese    |      0.1   |      0.132 |\n",
      "| dummy-most_frequent | x-ginco        | Maltese    |      0.053 |      0.229 |\n",
      "| Model               | Test Dataset   | Language   |   Macro F1 |   Micro F1 |\n",
      "|:--------------------|:---------------|:-----------|-----------:|-----------:|\n",
      "| dummy-stratified    | x-ginco        | Slovenian  |      0.128 |      0.143 |\n",
      "| dummy-most_frequent | x-ginco        | Slovenian  |      0.028 |      0.125 |\n",
      "| Model               | Test Dataset   | Language   |   Macro F1 |   Micro F1 |\n",
      "|:--------------------|:---------------|:-----------|-----------:|-----------:|\n",
      "| dummy-stratified    | x-ginco        | Turkish    |      0.129 |      0.14  |\n",
      "| dummy-most_frequent | x-ginco        | Turkish    |      0.03  |      0.138 |\n",
      "| Model               | Test Dataset   | Language   |   Macro F1 |   Micro F1 |\n",
      "|:--------------------|:---------------|:-----------|-----------:|-----------:|\n",
      "| dummy-stratified    | x-ginco        | Ukrainian  |      0.056 |      0.064 |\n",
      "| dummy-most_frequent | x-ginco        | Ukrainian  |      0.028 |      0.125 |\n"
     ]
    }
   ],
   "source": [
    "# For each language, create a table with results\n",
    "\n",
    "def results_table_lang(lang_results_df, lang):\n",
    "    dataset_df = lang_results_df[lang_results_df[\"Language\"] == lang]\n",
    "\n",
    "    # Sort values based on highest Macro F1\n",
    "    dataset_df = dataset_df.sort_values(by=\"Macro F1\", ascending=False)\n",
    "\n",
    "    # Round scores to 3 decimal places\n",
    "    dataset_df[\"Macro F1\"] = dataset_df[\"Macro F1\"].round(3)\n",
    "\n",
    "    dataset_df[\"Micro F1\"] = dataset_df[\"Micro F1\"].round(3)\n",
    "\n",
    "    print(dataset_df.to_markdown(index=False))\n",
    "\n",
    "    return dataset_df\n",
    "\n",
    "\n",
    "lang_result_file = open(\"results/language-specific-results.md\", \"w\")\n",
    "\n",
    "for lang in [\"Albanian\", \"Catalan\", \"Croatian\", \"English\", \"Greek\", \"Icelandic\", \"Macedonian\", \"Maltese\", \"Slovenian\", \"Turkish\", \"Ukrainian\"]:\n",
    "\n",
    "    current_df = results_table_lang(lang_results_df, lang)\n",
    "    \n",
    "    lang_result_file.write(\"\\n## {}\\n\\n\".format(lang))\n",
    "    lang_result_file.write(current_df.to_markdown(index=False))\n",
    "    lang_result_file.write(\"\\n\\n------------------------------------------\\n\")\n",
    "\n",
    "lang_result_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPTC_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
